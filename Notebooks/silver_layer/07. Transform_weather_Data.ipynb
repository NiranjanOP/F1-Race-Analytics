{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dceefd76-f773-4702-91d7-bcda621bcb77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer Transformation – Weather Data\n",
    "\n",
    "This notebook processes the raw **bronze.weather_data** table into the **silver.weather_data** table.\n",
    "\n",
    "### Steps performed:\n",
    "1. **Read** the raw weather data from the Bronze layer.  \n",
    "2. **Clean & Transform**:  \n",
    "   - Remove duplicate records based on `weather_id` and `timestamp`.  \n",
    "   - Standardize `wind_direction` to uppercase.  \n",
    "   - Apply basic data quality filters (valid ranges for temperature and humidity).  \n",
    "3. **Write** the cleaned data into the Silver layer as a Delta table.  \n",
    "\n",
    "**Output:**  \n",
    "A curated `silver.weather_data` table ready for downstream analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7887ee3a-9898-408a-a2b5-8a03976c45c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "from pyspark.sql.functions import col, upper\n",
    "\n",
    "# Read from Bronze\n",
    "bronze_weather_df = spark.read.format(\"delta\").table(\"bronze.weather_data\")\n",
    "\n",
    "# Transformations / Cleaning\n",
    "silver_weather_df = (\n",
    "    bronze_weather_df\n",
    "    # Remove duplicates\n",
    "    .dropDuplicates([\"weather_id\", \"timestamp\"])\n",
    "    # Ensure wind_direction is uppercase\n",
    "    .withColumn(\"wind_direction\", upper(col(\"wind_direction\")))\n",
    "    # Basic sanity filters\n",
    "    .filter(col(\"track_temperature\") > -50)   # remove invalid values\n",
    "    .filter(col(\"air_temperature\") > -50)     # remove invalid values\n",
    "    .filter(col(\"humidity\").between(0, 100))  # valid humidity %\n",
    ")\n",
    "\n",
    "# Write to Silver\n",
    "(\n",
    "    silver_weather_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")   # for first run, switch to \"append\" for incremental loads\n",
    "    .saveAsTable(\"silver.weather_data\")\n",
    ")\n",
    "\n",
    "print(\"✅ weather_data table created successfully in silver layer\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07. Transform_weather_Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

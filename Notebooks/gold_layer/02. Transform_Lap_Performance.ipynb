{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7a6d3dd-85b0-49d9-8b88-8596ae0cf3c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold Layer â€“ Lap Performance\n",
    "\n",
    "## Objective\n",
    "This notebook creates the `gold.lap_performance` table by combining lap times, telemetry, and weather data.  \n",
    "It focuses on building a comprehensive lap-level dataset that enables performance analytics.\n",
    "\n",
    "## Steps\n",
    "1. Load Silver tables: `lap_times`, `telemetry_data`, `weather_data`.  \n",
    "2. Join on `session_key` and `lap_number` where applicable.  \n",
    "3. Compute key performance indicators (KPIs):\n",
    "   - Average sector times  \n",
    "   - Speed metrics (max, min, avg per lap)  \n",
    "   - Tyre stint duration and compound  \n",
    "   - Weather impact (track temperature, rainfall)  \n",
    "4. Add derived flags:\n",
    "   - `is_fastest_lap` per race  \n",
    "   - `pit_lap` indicator  \n",
    "5. Remove duplicates and null handling.  \n",
    "6. Write the final enriched dataset into the Gold layer as `gold.lap_performance`.  \n",
    "7. Optimize table with ZORDER on `(session_key, driver_number, lap_number)`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edad38e4-9f55-4343-9f54-5ed415db5d47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1. Load Silver tables\n",
    "lap_times = spark.table(\"silver.lap_times\")\n",
    "telemetry = spark.table(\"silver.telemetry_data\")\n",
    "weather = spark.table(\"silver.weather_data\")\n",
    "\n",
    "# 2. Join lap_times with telemetry (driver, lap, session)\n",
    "lap_perf = (\n",
    "    lap_times.alias(\"lt\")\n",
    "    .join(\n",
    "        telemetry.alias(\"td\"),\n",
    "        on=[\n",
    "            \"driver\", \"lap_number\", \"session_key\"\n",
    "        ],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Aggregate telemetry metrics per lap\n",
    "telemetry_agg = (\n",
    "    telemetry.groupBy(\"driver\", \"lap_number\", \"session_key\")\n",
    "    .agg(\n",
    "        F.avg(\"Speed\").alias(\"avg_speed\"),\n",
    "        F.max(\"Speed\").alias(\"max_speed\"),\n",
    "        F.min(\"Speed\").alias(\"min_speed\"),\n",
    "        F.avg(\"RPM\").alias(\"avg_rpm\"),\n",
    "        F.avg(\"Throttle\").alias(\"avg_throttle\"),\n",
    "        F.avg(\"Brake\").alias(\"avg_brake\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4. Join aggregated telemetry to lap_times\n",
    "lap_perf = (\n",
    "    lap_times\n",
    "    .join(\n",
    "        telemetry_agg,\n",
    "        on=[\"driver\", \"lap_number\", \"session_key\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. Add weather conditions (closest time match per session)\n",
    "weather_agg = (\n",
    "    weather.groupBy(\"session_key\")\n",
    "    .agg(\n",
    "        F.avg(\"TrackTemp\").alias(\"avg_track_temp\"),\n",
    "        F.avg(\"AirTemp\").alias(\"avg_air_temp\"),\n",
    "        F.avg(\"Humidity\").alias(\"avg_humidity\"),\n",
    "        F.avg(\"Rainfall\").alias(\"avg_rainfall\")\n",
    "    )\n",
    ")\n",
    "\n",
    "lap_perf = lap_perf.join(weather_agg, on=\"session_key\", how=\"left\")\n",
    "\n",
    "# 6. Derived flags\n",
    "# Window by session_key for fastest lap\n",
    "w = Window.partitionBy(\"session_key\").orderBy(F.col(\"lap_time\").asc_nulls_last())\n",
    "lap_perf = lap_perf.withColumn(\"row_num\", F.row_number().over(w))\n",
    "lap_perf = lap_perf.withColumn(\"is_fastest_lap\", F.when(F.col(\"row_num\") == 1, True).otherwise(False))\n",
    "lap_perf = lap_perf.drop(\"row_num\")\n",
    "\n",
    "# Pit stop flag\n",
    "lap_perf = lap_perf.withColumn(\"pit_lap\", F.when(F.col(\"pit_in_time\").isNotNull() | F.col(\"pit_out_time\").isNotNull(), True).otherwise(False))\n",
    "\n",
    "# 7. Clean duplicates\n",
    "lap_perf = lap_perf.dropDuplicates()\n",
    "\n",
    "# 8. Write to Gold layer\n",
    "(\n",
    "    lap_perf.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"gold.lap_performance\")\n",
    ")\n",
    "\n",
    "# 9. Optimize\n",
    "spark.sql(\"OPTIMIZE gold.lap_performance ZORDER BY (session_key, driver, lap_number)\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02. Transform_Lap_Performance",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
